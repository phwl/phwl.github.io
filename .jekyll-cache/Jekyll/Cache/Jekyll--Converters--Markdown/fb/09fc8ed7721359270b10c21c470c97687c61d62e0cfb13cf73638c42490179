I"∑Z<p>::: {.maketitle}
Research in the Computer Engineering Lab {#research-in-the-computer-engineering-lab .titleHead}
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-</p>

<p>::: {.author}
:::</p>

<p>\</p>

<p>::: {.date}
[February 28, 2020]{.cmr-12}
:::
:::</p>

<p>The Computer Engineering Lab focuses on how to use field programmable
gate array, VLSI and parallel processor technologies to solve difficult
computing problems. We seek novel architectures, applications and design
techniques for problems which combine signal processing and machine
learning.</p>

<h3 id="1-titlemark-x1-10001machine-learning-machine-learning-sectionhead">[1 ]{.titlemark} []{#x1-10001}Machine Learning {#machine-learning .sectionHead}</h3>

<h4 id="11-titlemark-x1-200011low-precision-neural-networks-low-precision-neural-networks-subsectionhead">[1.1 ]{.titlemark} []{#x1-20001.1}Low Precision Neural Networks {#low-precision-neural-networks .subsectionHead}</h4>

<p>In 2017, in collaboration with Xilinx Research Labs, our FINN paper was
one of the first to demonstrate that binarized neural networks are an
excellent match to FPGA
architectures¬†[[]{#page.3}<a href="overview.html#X1-UFGBLJV:17">3</a>].
Implementations exploiting binary weights have led to the highest
performance FPGA implementations of convolutional neural networks. We
further improved the accuracy using Symmetric
Quantization¬†[<a href="overview.html#X1-FFBL:18">1</a>], reporting state of the
art results. We have also developed a fully parallel implementation of
ternary networks which achieved the highest reported performance on an
FPGA for small convolutional neural
networks¬†[<a href="overview.html#X1-TKHBMZL:19">2</a>].</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X1-}Julian Faraone et al. ‚ÄúSYQ: Learning
Symmetric Quantization For Efficient Deep Neural Networks‚Äù. In:
[Proc. Computer Vision]{.cmti-10x-x-109} [and Pattern Recognition
(CVPR)]{.cmti-10x-x-109}. Utah, US, June 2018.
[[d]{.small-caps}[o]{.small-caps}[i]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="https://doi.org/10.1109/CVPR.2018.00452">10.1109/CVPR.2018.00452</a>.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="syq_cvpr18.pdf">[syq_cvpr18.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[2]</dt>
  <dd>
    <p>Stephen Tridgell et al. ‚ÄúUnrolling Ternary Neural Networks‚Äù. In:
[ACM]{.cmti-10x-x-109} [Trans. Reconfigurable Technol. Syst.
]{.cmti-10x-x-109}12.4 (Oct. 2019), 22:1‚Äì22:23.
[[i]{.small-caps}[s]{.small-caps}[s]{.small-caps}[n]{.small-caps}]{.cmcsc-10x-x-109}:
1936-7406.
[[d]{.small-caps}[o]{.small-caps}[i]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="https://doi.org/10.1145/3359983">10.1145/3359983</a>.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="ternary_trets19.pdf">[ternary_trets19.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[3]</dt>
  <dd>
    <p>Yaman Umuroglu et al. ‚ÄúFINN: A Framework for Fast, Scalable
Binarized Neural Network Inference‚Äù. In: [Proc. ACM/SIGDA
International Symposium]{.cmti-10x-x-109} [on Field-Programmable
Gate Arrays (FPGA)]{.cmti-10x-x-109}. Source code available from
<a href="https://github.com/Xilinx/BNN-PYNQ">https://github.com/Xilinx/BNN-PYNQ</a>. 2017, pp. 65‚Äì74.
[[d]{.small-caps}[o]{.small-caps}[i]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="https://doi.org/10.1145/3020078.3021744">10.1145/3020078.3021744</a>.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="bnn_fpga17.pdf">[bnn_fpga17.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>

<h4 id="12-titlemark-x1-300012fpga-architectures-for-low-precision-neural-networks-fpga-architectures-for-low-precision-neural-networks-subsectionhead">[1.2 ]{.titlemark} []{#x1-30001.2}FPGA Architectures for Low Precision Neural Networks {#fpga-architectures-for-low-precision-neural-networks .subsectionHead}</h4>

<p>We have also been exploring how FPGA architectures can be modified to
better support the implementation of low-precision neural networks. In
2019, collaborating with Fudan University, we developed PIR-DSP, a
digital signal processing (DSP) block compatible with the Xilinx DSP38E2
which supports 9, 4 and 2-bit multiply-accumulation (MAC) operations,
offering a 6, 12, and 24[√ó ]{.cmsy-10x-x-109}improvement in MACs per DSP
respectively¬†[[]{#page.4}<a href="overview.html#X2-RZWL:19">1</a>]. We also
developed LUXOR, which are vendor-agnostic (LUXOR) and vendor-specific
(LUXOR+) modifications to the Xilinx and Intel logic elements to allow
the efficient implementation of compressor trees. We demonstrate that
LUXOR can deliver an average reduction of 13-19micro-benchmarks from a
variety of domains. Binarized neural networks benefit the most with an
average reduction of 37-47utilization, which is due to the
highly-efficient mapping of the XnorPopcount operation on our proposed
LUXOR+ logic cells.</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X2-}SeyedRamin Rasoulinezhad et al. ‚ÄúPIR-DSP: An
FPGA DSP block Architecture for Multi-Precision Deep Neural
Networks‚Äù. In: [Proc. IEEE Symposium on Field-Programmable Custom
Computing]{.cmti-10x-x-109} [Machines (FCCM)]{.cmti-10x-x-109}.
2019, pp. 1‚Äì8.
[[d]{.small-caps}[o]{.small-caps}[i]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="https://doi.org/10.1109/FCCM.2019.00015">10.1109/FCCM.2019.00015</a>.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="pirdsp_fccm19.pdf">[pirdsp_fccm19.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>

<h4 id="13-titlemark-x1-400013on-chip-training-on-chip-training-subsectionhead">[1.3 ]{.titlemark} []{#x1-40001.3}On-Chip Training {#on-chip-training .subsectionHead}</h4>

<p>We have developed a mixed-precision on-chip training implementation of
the SWALP algorithm on the Xilinx Zynq
platform¬†[[]{#page.5}<a href="overview.html#X3-FFBVL:19">1</a>]. Using
predominantly 8-bit integer numbers, block floating-point quantisation
and stochastic weight averaging techniques are applied during training
to avoid any degradation in accuracy. By using floating-point for the
small number of high-precision operations required, we achieve a 0.5%
accuracy improvement for the MNIST and CIFAR10 benchmarks, with results
within 0.1% of floating point.</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X3-}Sean Fox et al. ‚ÄúTraining Deep Neural
Networks in Low-Precision with High Accuracy using FPGAs‚Äù. In:
[Proc. International Conference on]{.cmti-10x-x-109} [Field
Programmable Technology (FPT)]{.cmti-10x-x-109}. Best Paper Award
Candidate. 2019, to appear.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="lptrain_fpt19.pdf">[lptrain_fpt19.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>

<h4 id="14-titlemark-x1-500014kernel-methods-kernel-methods-subsectionhead">[1.4 ]{.titlemark} []{#x1-50001.4}Kernel Methods {#kernel-methods .subsectionHead}</h4>

<p>We have developed a family of implementations of kernel methods which
can perform simultaneous learning and prediction with different
tradeoffs between capacity, performance, and area. Our microcoded kernel
recursive least squares (KRLS) and kernel normalised least mean squares
(KNLMS) implementations achieves an order of magnitude improvement in
throughput over a microprocessor, and is
programmable¬†[<a href="overview.html#X4-Pang:2016:MKR:3002131.2950061">3</a>].
Our fully pipelined implementation of KNLMS achieves 161¬†GFLOPS, this
being a 10x speedup over a desktop processor and a 2.66x speedup over a
GPU¬†[<a href="overview.html#X4-Fraser:2017:FIK:3166118.3106744">2</a>]. We
developed the [braiding]{.cmti-10x-x-109} technique which overcomes
dependencies by expressing the output as a combination of the earlier
state and other examples in the pipeline. This was applied to the Naive
Online regularised Risk Minimization Algorithm (NORMA), achieving a
latency of less than 100¬†ns¬†[<a href="overview.html#X4-TMFL:15">4</a>]. We also
developed a delayed update scheme to achieve 250¬†Gop/s, a 1.8x
improvement on the state of the art and 12x higher performance than the
standard KNLMS algorithm¬†[<a href="overview.html#X4-FL:20">1</a>] .</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X4-}Nicholas J. Fraser and Philip H. W. Leong.
‚ÄúKernel Normalised Least Mean Squares with Delayed Model
Adaptation‚Äù. In: [ACM Trans.]{.cmti-10x-x-109} [Reconfigurable
Technol. Syst. ]{.cmti-10x-x-109}(2020), to appear (accepted 17 Dec
2019).
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="dknlms_trets20.pdf">[dknlms_trets20.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[2]</dt>
  <dd>
    <p>Nicholas J. Fraser et al. ‚ÄúFPGA Implementations of Kernel Normalised
Least Mean Squares Processors‚Äù. In: [ACM Trans.
Reconfigurable]{.cmti-10x-x-109} [Technol. Syst.
]{.cmti-10x-x-109}10.4 (Dec. 2017), 26:1‚Äì26:20.
[[i]{.small-caps}[s]{.small-caps}[s]{.small-caps}[n]{.small-caps}]{.cmcsc-10x-x-109}:
1936-7406.
[[d]{.small-caps}[o]{.small-caps}[i]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="https://doi.org/10.1145/3106744">10.1145/3106744</a>.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="knlms_trets17.pdf">[knlms_trets17.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[3]</dt>
  <dd>
    <p>Yeyong Pang et al. ‚ÄúA Microcoded Kernel Recursive Least Squares
Processor Using FPGA Technology‚Äù. In: [ACM Trans.
Reconfigurable]{.cmti-10x-x-109} [Technol. Syst.
]{.cmti-10x-x-109}10.1 (Sept. 2016), 5:1‚Äì5:22.
[[i]{.small-caps}[s]{.small-caps}[s]{.small-caps}[n]{.small-caps}]{.cmcsc-10x-x-109}:
1936-7406.
[[d]{.small-caps}[o]{.small-caps}[i]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="https://doi.org/10.1145/2950061">10.1145/2950061</a>.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="kproc_trets16.pdf">[kproc_trets16.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[4]</dt>
  <dd>
    <p>Stephen Tridgell et al. ‚ÄúBraiding: a Scheme for Resolving Hazards in
kernel adaptive filters‚Äù. In: [Proc. International Conference on
Field]{.cmti-10x-x-109} [Programmable Technology
(FPT)]{.cmti-10x-x-109}. Queenstown, 2015, pp. 136‚Äì143.
[[d]{.small-caps}[o]{.small-caps}[i]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="https://doi.org/10.1109/FPT.2015.7393140">10.1109/FPT.2015.7393140</a>.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="braiding_fpt15.pdf">[braiding_fpt15.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>

<h3 id="2-titlemark-x1-60002reconfigurable-computing-reconfigurable-computing-sectionhead">[2 ]{.titlemark} []{#x1-60002}Reconfigurable Computing {#reconfigurable-computing .sectionHead}</h3>

<h4 id="21-titlemark-x1-700021fpga-architectures-fpga-architectures-subsectionhead">[2.1 ]{.titlemark} []{#x1-70002.1}FPGA Architectures {#fpga-architectures .subsectionHead}</h4>

<p>We developed analytical models that relate FPGA architectural parameters
to the delay¬†[[]{#page.6}<a href="overview.html#X5-HWYCL:09">2</a>], logic size
and depth¬†[<a href="overview.html#X5-DLWLL:11">1</a>] of an FPGA implementation.
We also proposed [hybrid FPGAs ]{.cmti-10x-x-109}and a methodology to
optimize coarse-grained floating point units (FPUs) which used common
subgraph elimination to determine the best mix of blocks within an
FPU¬†[<a href="overview.html#X5-YSLLW:12">3</a>].</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X5-}Joydip Das et al. ‚ÄúAn Analytical Model
Relating FPGA Architecture to Logic Density and Depth‚Äù. In: [IEEE
Transactions on VLSI Systems]{.cmti-10x-x-109} 9.12 (2011), pp.
2229‚Äì2242.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="anyl_tvlsi11.pdf">[anyl_tvlsi11.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[2]</dt>
  <dd>
    <p>Eddie Hung et al. ‚ÄúA Detailed Delay Path Model for FPGAs‚Äù. In:
[Proc.]{.cmti-10x-x-109} [International Conference on Field
Programmable Technology (FPT)]{.cmti-10x-x-109}. Sydney, 2009, pp.
96‚Äì103.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="delay_fpt09.pdf">[delay_fpt09.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[3]</dt>
  <dd>
    <p>ChiWai Yu et al. ‚ÄúOptimizing Floating Point Units in Hybrid FPGAs‚Äù.
In: [IEEE Transactions on VLSI Systems ]{.cmti-10x-x-109}20 (7
2012), pp. 1295‚Äì1303.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="ofpu_tvlsi12.pdf">[ofpu_tvlsi12.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>

<h4 id="22-titlemark-x1-800022random-number-generators-random-number-generators-subsectionhead">[2.2 ]{.titlemark} []{#x1-80002.2}Random Number Generators {#random-number-generators .subsectionHead}</h4>

<p>We proposed compact true and pseudo random number generators which can
be efficiently implemented on
FPGAs¬†[[]{#page.7}<a href="overview.html#X6-TLL:03">2</a>]. Seminal work on
Gaussian number generators on FPGAs were also reviewed and state of the
art implementations based on different techniques
proposed¬†[<a href="overview.html#X6-TLLV:07">1</a>].</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X6-}David B. Thomas et al. ‚ÄúGaussian random
number generators‚Äù. In: [ACM Computing Surveys]{.cmti-10x-x-109}
39.4 (2007), 11:1‚Äì11:38.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="grng_acmcs07.pdf">[grng_acmcs07.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[2]</dt>
  <dd>
    <p>K.H. Tsoi, K.H. Leung, and P.H.W. Leong. ‚ÄúCompact FPGA-based True
and Pseudo Random Number Generators‚Äù. In: [Proc.
IEEE]{.cmti-10x-x-109} [Symposium on Field-Programmable Custom
Computing Machines]{.cmti-10x-x-109} [(FCCM)]{.cmti-10x-x-109}.
California, 2003, pp. 51‚Äì61.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="tprng_fccm03.pdf">[tprng_fccm03.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>

<h4 id="23-titlemark-x1-900023system-implementation-board-and-vlsi-level-system-implementation-board-and-vlsi-level-subsectionhead">[2.3 ]{.titlemark} []{#x1-90002.3}System Implementation (Board and VLSI Level) {#system-implementation-board-and-vlsi-level .subsectionHead}</h4>

<p>We recognised that FPGA to processor transfers via the PCI-bus
introduced substantial latency to many applications, and addressed it by
proposing Pilchard, an FPGA card which plugged directly into a memory
slot of a high-performance
processor¬†[<a href="overview.html#X7-LLCTKWL:01">2</a>]. We developed the highest
performance structured ASIC with a 26/5x improvement in area/delay
compared to an FPGA, which is customised using a minimum of 3 masks,
i.e. two metals and one via¬†[<a href="overview.html#X7-HACYCLP:13">1</a>].</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X7-}Man-Ho Ho et al. ‚ÄúArchitecture and Design
Flow for a Highly Efficient Structured ASIC‚Äù. In: [IEEE Transactions
on VLSI Systems ]{.cmti-10x-x-109}21.3 (2013), pp. 424‚Äì433.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="sasic_tvlsi12.pdf">[sasic_tvlsi12.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[2]</dt>
  <dd>
    <p>P.H.W. Leong et al. ‚ÄúPilchard - A Reconfigurable Computing Platform
with Memory Slot Interface‚Äù. In: [Proc. IEEE Symposium
on]{.cmti-10x-x-109} [Field-Programmable Custom Computing Machines
(FCCM)]{.cmti-10x-x-109}. Selected as one of the 25 most significant
papers from the first 20 years of FCCM. California, 2001, pp.
170‚Äì179.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="pilchard_fccm01.pdf">[pilchard_fccm01.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>

<h4 id="24-titlemark-x1-1000024financial-engineering-financial-engineering-subsectionhead">[2.4 ]{.titlemark} []{#x1-100002.4}Financial Engineering {#financial-engineering .subsectionHead}</h4>

<p>We were the first to demonstrate acceleration of Monte Carlo (MC)
techniques for the pricing of complex derivatives using
FPGAs¬†[[]{#page.8}<a href="overview.html#X8-ZLHTCLCL:05">1</a>]. Our pipelined MC
core implemented the Brace, Gatarek and Musiela (BGM) interest rate
model and was 25 times faster than a software implementation on a
desktop processor.</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X8-}G. L. Zhang et al. ‚ÄúReconfigurable
Acceleration for Monte Carlo based Financial Simulation‚Äù. In: [Proc.
International Conference on Field]{.cmti-10x-x-109} [Programmable
Technology (FPT)]{.cmti-10x-x-109}. Singapore, 2005, pp. 215‚Äì222.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="bgm_fpt05.pdf">[bgm_fpt05.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>

<h4 id="25-titlemark-x1-1100025cryptography-cryptography-subsectionhead">[2.5 ]{.titlemark} []{#x1-110002.5}Cryptography {#cryptography .subsectionHead}</h4>

<p>We reported the most efficient FPGA implementations of an elliptic curve
processor¬†[<a href="overview.html#X9-LL:02">1</a>], the IDEA
algorithm¬†[[LCTL:00]{.cmbx-10x-x-109}], Montgomery
multiplication¬†[<a href="overview.html#X9-TCL:02">2</a>] and
RC4¬†[<a href="overview.html#X9-TLL:02">3</a>]. We also novel techniques to
implement physically uncloneable functions
(PUFs)¬†[<a href="overview.html#X9-YLX:12">4</a>].</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X9-}P.H.W. Leong and K.H. Leung. ‚ÄúA Microcoded
Elliptic Curve Processor using FPGA Technology‚Äù. In: [IEEE
Transactions on VLSI Systems]{.cmti-10x-x-109} 10.5 (2002), pp.
550‚Äì559.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="ecc_tvlsi02.pdf">[ecc_tvlsi02.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[2]</dt>
  <dd>
    <p>K.H. Tsoi, O.Y.H. Cheung, and P.H.W. Leong. ‚ÄúA Variable-Radix
Systolic Montgomery Multiplier‚Äù. In: [Proc. IEEE Symposium
on]{.cmti-10x-x-109} [Field-Programmable Custom Computing Machines
(FCCM)]{.cmti-10x-x-109}. California, 2002.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="mm_fccm02.pdf">[mm_fccm02.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[3]</dt>
  <dd>
    <p>K.H. Tsoi, K.H. Lee, and P.H.W. Leong. ‚ÄúA Massively Parallel RC4 Key
Search Engine‚Äù. In: [Proc. IEEE Symposium on
Field-Programmable]{.cmti-10x-x-109} [Custom Computing Machines
(FCCM)]{.cmti-10x-x-109}. California, 2002, pp. 13‚Äì21.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="rc4_fccm02.pdf">[rc4_fccm02.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[4]</dt>
  <dd>
    <p>Haile Yu, Philip H.W. Leong, and Qiang Xu. ‚ÄúAn FPGA Chip
Identification Generator Using Configurable Ring Oscillator‚Äù. In:
[IEEE]{.cmti-10x-x-109} [Transactions on VLSI Systems
]{.cmti-10x-x-109}20.11 (2012), pp. 2198‚Äì2207.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="id_tvlsi12.pdf">[id_tvlsi12.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>

<h3 id="3-titlemark-x1-120003biomedical-engineering-biomedical-engineering-sectionhead">[3 ]{.titlemark} []{#x1-120003}Biomedical Engineering {#biomedical-engineering .sectionHead}</h3>

<h4 id="31-titlemark-x1-1300031arrhythmia-classification-arrhythmia-classification-subsectionhead">[3.1 ]{.titlemark} []{#x1-130003.1}Arrhythmia Classification {#arrhythmia-classification .subsectionHead}</h4>

<p>We showed that the morphology of intracardiac electrocardiogram signals
can be used to improve classification accuracy in implantable cardiac
defibrillators (ICD)¬†[[]{#page.9}<a href="overview.html#X10-LJ:92">2</a>], and
that it could be implemented in low-power analogue
VLSI¬†[<a href="overview.html#X10-L:92">4</a>, <a href="overview.html#X10-LJ:95">1</a>]. This
led to a patent¬†[<a href="overview.html#X10-LJ:94">3</a>] that has been cited by
all of the major ICD manufacturers such as Medtronic, Cardiac Pacemakers
and Siemens, St. Jude Medical, and Pacesetter, and is being used in
their commercial devices.</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X10-}P. H. W. Leong and M.A. Jabri. ‚ÄúA Low Power
VLSI Arrhythmia Classifier‚Äù. In: [IEEE Transactions on Neural
Networks ]{.cmti-10x-x-109}6.6 (Nov. 1995), pp. 1435‚Äì1445.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="matic_tnn95.pdf">[matic_tnn95.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[2]</dt>
  <dd>
    <p>P.H.W. Leong and M. Jabri. ‚ÄúMATIC - an intracardiac tachycardia
classification system‚Äù. In: [Pacing and Clinical
Electrophysiology]{.cmti-10x-x-109} [(PACE) ]{.cmti-10x-x-109}15
(Sept. 1992), pp. 1317‚Äì1331.</p>
  </dd>
  <dt>[3]</dt>
  <dd>
    <p>P.H.W. Leong and M.A. Jabri. [A method and system for
automatically]{.cmti-10x-x-109} [classifying intracardiac
electrograms]{.cmti-10x-x-109}. US Patent 5,280,792. University of
Sydney. Jan. 1994.</p>
  </dd>
  <dt>[4]</dt>
  <dd>
    <p>Philip Leong. ‚ÄúArrhythmia classification using low power VLSI‚Äù. PhD
thesis. University of Sydney, 1992.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="phdthesis.pdf">[phdthesis.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>

<h4 id="32-titlemark-x1-1400032respiratory-artefact-removal-respiratory-artefact-removal-subsectionhead">[3.2 ]{.titlemark} []{#x1-140003.2}Respiratory Artefact Removal {#respiratory-artefact-removal .subsectionHead}</h4>

<p>We have developed feature selection techniques for time series problems,
and applied them to a number of different applications including
respiratory artefact
removal¬†[[]{#page.10}<a href="overview.html#X11-PTRML:16">2</a>,
<a href="overview.html#X11-PLRGJKT:17">1</a>]. A parameterised generator is used
to produce a large set of candidate features, and a number of
complementary metrics used to select a subset. This technique was found
to produce significantly improved results in the abovementioned
application domains.</p>

<dl>
  <dt>[1]</dt>
  <dd>
    <p><a href="overview.html"></a>{#X11-}Thuy T. Pham et al. ‚ÄúAutomated Quality
Control of Forced Oscillation Measurements: Respiratory Artifact
Detection with Advanced Feature Extraction‚Äù. In: [Journal of Applied
Physiology ]{.cmti-10x-x-109}123 (4 May 2017), jap.00726.2016.
[[d]{.small-caps}[o]{.small-caps}[i]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="https://doi.org/10.1152/japplphysiol.00726.2016">10.1152/japplphysiol.00726.2016</a>.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="fot_jappl17.pdf">[fot_jappl17.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
  <dt>[2]</dt>
  <dd>
    <p>Thuy T. Pham et al. ‚ÄúRespiratory Artefact Removal in Forced
Oscillation Measurements: A Machine Learning Approach‚Äù. In: [IEEE
Transactions on Biomedical Engineering ]{.cmti-10x-x-109}64.8 (Aug.
2017), pp. 1679‚Äì1687.
[[i]{.small-caps}[s]{.small-caps}[s]{.small-caps}[n]{.small-caps}]{.cmcsc-10x-x-109}:
0018-9294.
[[d]{.small-caps}[o]{.small-caps}[i]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="https://doi.org/10.1109/TBME.2016.2554599">10.1109/TBME.2016.2554599</a>.
[[u]{.small-caps}[r]{.small-caps}[l]{.small-caps}]{.cmcsc-10x-x-109}:
<a href="fot_tbme16.pdf">[fot_tbme16.pdf]{.cmtt-10x-x-109}</a>{.url}.</p>
  </dd>
</dl>
:ET